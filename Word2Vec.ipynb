{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishalveerareddy/Word2VecGOT/blob/master/Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-ui9ZiGmarP",
        "colab_type": "code",
        "outputId": "432b997a-c910-40b9-984a-fad19b0967df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "! git clone \"https://github.com/llSourcell/word_vectors_game_of_thrones-LIVE.git\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'word_vectors_game_of_thrones-LIVE'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "Unpacking objects:   4% (1/23)   \rUnpacking objects:   8% (2/23)   \rUnpacking objects:  13% (3/23)   \rUnpacking objects:  17% (4/23)   \rUnpacking objects:  21% (5/23)   \rUnpacking objects:  26% (6/23)   \rUnpacking objects:  30% (7/23)   \rUnpacking objects:  34% (8/23)   \rUnpacking objects:  39% (9/23)   \rUnpacking objects:  43% (10/23)   \rUnpacking objects:  47% (11/23)   \rUnpacking objects:  52% (12/23)   \rUnpacking objects:  56% (13/23)   \rUnpacking objects:  60% (14/23)   \rremote: Total 23 (delta 0), reused 0 (delta 0), pack-reused 23\u001b[K\n",
            "Unpacking objects:  65% (15/23)   \rUnpacking objects:  69% (16/23)   \rUnpacking objects:  73% (17/23)   \rUnpacking objects:  78% (18/23)   \rUnpacking objects:  82% (19/23)   \rUnpacking objects:  86% (20/23)   \rUnpacking objects:  91% (21/23)   \rUnpacking objects:  95% (22/23)   \rUnpacking objects: 100% (23/23)   \rUnpacking objects: 100% (23/23), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0eDdX6goRwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import codecs\n",
        "import glob\n",
        "import logging\n",
        "import multiprocessing\n",
        "import os\n",
        "import pprint\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hiCbLAArB8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import nltk\n",
        "import gensim.models.word2vec as w2v\n",
        "import sklearn.manifold\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swCXMZW8rENo",
        "colab_type": "code",
        "outputId": "0a432ab2-7b65-4502-a89f-5509b4ba2ae2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%pylab inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HQG7CMHrYDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1kt4MkVra8X",
        "colab_type": "code",
        "outputId": "472da3bf-2b93-43bc-ca21-b33126bf34f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ytay5t4rcsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "book_filenames = sorted(glob.glob(\"/content/word_vectors_game_of_thrones-LIVE/data/*.txt\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBHP1I86r7xA",
        "colab_type": "code",
        "outputId": "ce5dfdb7-5ac8-47ae-d1ef-1ac215f5690e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(\"Found books:\")\n",
        "book_filenames"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found books:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/word_vectors_game_of_thrones-LIVE/data/got1.txt',\n",
              " '/content/word_vectors_game_of_thrones-LIVE/data/got2.txt',\n",
              " '/content/word_vectors_game_of_thrones-LIVE/data/got3.txt',\n",
              " '/content/word_vectors_game_of_thrones-LIVE/data/got4.txt',\n",
              " '/content/word_vectors_game_of_thrones-LIVE/data/got5.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnPE5cPwsBNC",
        "colab_type": "code",
        "outputId": "c0982abd-a9ca-4f7a-f2c0-7eb1a76df7b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "corpus_raw = u\"\"\n",
        "for book_filename in book_filenames:\n",
        "    print(\"Reading '{0}'...\".format(book_filename))\n",
        "    with codecs.open(book_filename, \"r\", \"utf-8\") as book_file:\n",
        "        corpus_raw += book_file.read()\n",
        "    print(\"Corpus is now {0} characters long\".format(len(corpus_raw)))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading '/content/word_vectors_game_of_thrones-LIVE/data/got1.txt'...\n",
            "Corpus is now 1770659 characters long\n",
            "\n",
            "Reading '/content/word_vectors_game_of_thrones-LIVE/data/got2.txt'...\n",
            "Corpus is now 4071041 characters long\n",
            "\n",
            "Reading '/content/word_vectors_game_of_thrones-LIVE/data/got3.txt'...\n",
            "Corpus is now 6391405 characters long\n",
            "\n",
            "Reading '/content/word_vectors_game_of_thrones-LIVE/data/got4.txt'...\n",
            "Corpus is now 8107945 characters long\n",
            "\n",
            "Reading '/content/word_vectors_game_of_thrones-LIVE/data/got5.txt'...\n",
            "Corpus is now 9719485 characters long\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C10SpZj0sEqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3IsNmcysHYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_sentences = tokenizer.tokenize(corpus_raw)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtPqAEoDsJ2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentence_to_wordlist(raw):\n",
        "    clean = re.sub(\"[^a-zA-Z]\",\" \", raw)\n",
        "    words = clean.split()\n",
        "    return words\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6JGIbgGsNKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = []\n",
        "for raw_sentence in raw_sentences:\n",
        "    if len(raw_sentence) > 0:\n",
        "        sentences.append(sentence_to_wordlist(raw_sentence))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMAL4UUYsPed",
        "colab_type": "code",
        "outputId": "3b7f7f82-2d97-4c8c-c4f1-dd7e859e16b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(raw_sentences[5])\n",
        "print(sentence_to_wordlist(raw_sentences[5]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Heraldic crest by Virginia Norey.\n",
            "['Heraldic', 'crest', 'by', 'Virginia', 'Norey']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c1yMhDVsR0f",
        "colab_type": "code",
        "outputId": "3e19bd0f-6d07-45ae-fc9d-946f6915c28a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "token_count = sum([len(sentence) for sentence in sentences])\n",
        "print(\"The book corpus contains {0:,} tokens\".format(token_count))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The book corpus contains 1,818,103 tokens\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXippVC7sU1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ONCE we have vectors\n",
        "#step 3 - build model\n",
        "#3 main tasks that vectors help with\n",
        "#DISTANCE, SIMILARITY, RANKING\n",
        "\n",
        "# Dimensionality of the resulting word vectors.\n",
        "#more dimensions, more computationally expensive to train\n",
        "#but also more accurate\n",
        "#more dimensions = more generalized\n",
        "num_features = 300\n",
        "# Minimum word count threshold.\n",
        "min_word_count = 3\n",
        "\n",
        "# Number of threads to run in parallel.\n",
        "#more workers, faster we train\n",
        "num_workers = multiprocessing.cpu_count()\n",
        "\n",
        "# Context window length.\n",
        "context_size = 7\n",
        "\n",
        "# Downsample setting for frequent words.\n",
        "#0 - 1e-5 is good for this\n",
        "downsampling = 1e-3\n",
        "\n",
        "# Seed for the RNG, to make the results reproducible.\n",
        "#random number generator\n",
        "#deterministic, good for debugging\n",
        "seed = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca9Orj5msp81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "thrones2vec = w2v.Word2Vec(\n",
        "    sg=1,\n",
        "    seed=seed,\n",
        "    workers=num_workers,\n",
        "    size=num_features,\n",
        "    min_count=min_word_count,\n",
        "    window=context_size,\n",
        "    sample=downsampling\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQrMLgxxssMe",
        "colab_type": "code",
        "outputId": "69d25263-45b4-4d1c-d557-e3c9ff070ed7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "thrones2vec.build_vocab(sentences)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-07-21 13:22:44,067 : INFO : collecting all words and their counts\n",
            "2019-07-21 13:22:44,069 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2019-07-21 13:22:44,117 : INFO : PROGRESS: at sentence #10000, processed 140984 words, keeping 10280 word types\n",
            "2019-07-21 13:22:44,155 : INFO : PROGRESS: at sentence #20000, processed 279730 words, keeping 13558 word types\n",
            "2019-07-21 13:22:44,192 : INFO : PROGRESS: at sentence #30000, processed 420336 words, keeping 16598 word types\n",
            "2019-07-21 13:22:44,229 : INFO : PROGRESS: at sentence #40000, processed 556581 words, keeping 18324 word types\n",
            "2019-07-21 13:22:44,265 : INFO : PROGRESS: at sentence #50000, processed 686247 words, keeping 19714 word types\n",
            "2019-07-21 13:22:44,306 : INFO : PROGRESS: at sentence #60000, processed 828497 words, keeping 21672 word types\n",
            "2019-07-21 13:22:44,350 : INFO : PROGRESS: at sentence #70000, processed 973830 words, keeping 23093 word types\n",
            "2019-07-21 13:22:44,392 : INFO : PROGRESS: at sentence #80000, processed 1114967 words, keeping 24252 word types\n",
            "2019-07-21 13:22:44,434 : INFO : PROGRESS: at sentence #90000, processed 1260481 words, keeping 26007 word types\n",
            "2019-07-21 13:22:44,477 : INFO : PROGRESS: at sentence #100000, processed 1393203 words, keeping 26884 word types\n",
            "2019-07-21 13:22:44,522 : INFO : PROGRESS: at sentence #110000, processed 1532150 words, keeping 27809 word types\n",
            "2019-07-21 13:22:44,567 : INFO : PROGRESS: at sentence #120000, processed 1680961 words, keeping 28486 word types\n",
            "2019-07-21 13:22:44,607 : INFO : collected 29026 word types from a corpus of 1818103 raw words and 128868 sentences\n",
            "2019-07-21 13:22:44,609 : INFO : Loading a fresh vocabulary\n",
            "2019-07-21 13:22:44,660 : INFO : effective_min_count=3 retains 17277 unique words (59% of original 29026, drops 11749)\n",
            "2019-07-21 13:22:44,662 : INFO : effective_min_count=3 leaves 1802699 word corpus (99% of original 1818103, drops 15404)\n",
            "2019-07-21 13:22:44,719 : INFO : deleting the raw counts dictionary of 29026 items\n",
            "2019-07-21 13:22:44,723 : INFO : sample=0.001 downsamples 50 most-common words\n",
            "2019-07-21 13:22:44,725 : INFO : downsampling leaves estimated 1404424 word corpus (77.9% of prior 1802699)\n",
            "2019-07-21 13:22:44,810 : INFO : estimated required memory for 17277 words and 300 dimensions: 50103300 bytes\n",
            "2019-07-21 13:22:44,812 : INFO : resetting layer weights\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a8gApD3suMq",
        "colab_type": "code",
        "outputId": "93fcdf5b-d826-4961-abfc-659fd79b35ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "len(sentences)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128868"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvpELqpTsxW7",
        "colab_type": "code",
        "outputId": "b2185f34-63e6-477d-bebf-97da9a3c1311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "thrones2vec.train(sentences,total_examples=128868, epochs=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-07-21 13:28:03,934 : INFO : training model with 2 workers on 17277 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=7\n",
            "2019-07-21 13:28:05,089 : INFO : EPOCH 1 - PROGRESS: at 8.20% examples, 101810 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:06,129 : INFO : EPOCH 1 - PROGRESS: at 16.05% examples, 102764 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:07,169 : INFO : EPOCH 1 - PROGRESS: at 23.78% examples, 103013 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:08,199 : INFO : EPOCH 1 - PROGRESS: at 31.78% examples, 103604 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:09,212 : INFO : EPOCH 1 - PROGRESS: at 40.20% examples, 104206 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:10,251 : INFO : EPOCH 1 - PROGRESS: at 47.71% examples, 104138 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:11,293 : INFO : EPOCH 1 - PROGRESS: at 55.13% examples, 104107 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:12,327 : INFO : EPOCH 1 - PROGRESS: at 62.74% examples, 104246 words/s, in_qsize 2, out_qsize 1\n",
            "2019-07-21 13:28:13,344 : INFO : EPOCH 1 - PROGRESS: at 70.36% examples, 104380 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:14,401 : INFO : EPOCH 1 - PROGRESS: at 78.48% examples, 104151 words/s, in_qsize 4, out_qsize 1\n",
            "2019-07-21 13:28:15,430 : INFO : EPOCH 1 - PROGRESS: at 86.30% examples, 104198 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:16,475 : INFO : EPOCH 1 - PROGRESS: at 93.43% examples, 104079 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:17,364 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-07-21 13:28:17,368 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-07-21 13:28:17,371 : INFO : EPOCH - 1 : training on 1818103 raw words (1404254 effective words) took 13.4s, 104624 effective words/s\n",
            "2019-07-21 13:28:18,414 : INFO : EPOCH 2 - PROGRESS: at 7.09% examples, 97449 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:19,449 : INFO : EPOCH 2 - PROGRESS: at 15.06% examples, 100996 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:20,499 : INFO : EPOCH 2 - PROGRESS: at 22.68% examples, 101553 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:21,525 : INFO : EPOCH 2 - PROGRESS: at 30.62% examples, 102534 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:22,552 : INFO : EPOCH 2 - PROGRESS: at 38.96% examples, 103082 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:23,591 : INFO : EPOCH 2 - PROGRESS: at 46.57% examples, 103231 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:24,621 : INFO : EPOCH 2 - PROGRESS: at 54.05% examples, 103481 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:25,642 : INFO : EPOCH 2 - PROGRESS: at 61.71% examples, 103855 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:26,663 : INFO : EPOCH 2 - PROGRESS: at 69.09% examples, 104042 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:27,680 : INFO : EPOCH 2 - PROGRESS: at 77.28% examples, 104280 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:28,730 : INFO : EPOCH 2 - PROGRESS: at 85.13% examples, 104120 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:29,753 : INFO : EPOCH 2 - PROGRESS: at 92.42% examples, 104191 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:30,795 : INFO : EPOCH 2 - PROGRESS: at 99.54% examples, 104140 words/s, in_qsize 2, out_qsize 0\n",
            "2019-07-21 13:28:30,819 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-07-21 13:28:30,822 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-07-21 13:28:30,825 : INFO : EPOCH - 2 : training on 1818103 raw words (1404992 effective words) took 13.4s, 104532 effective words/s\n",
            "2019-07-21 13:28:31,864 : INFO : EPOCH 3 - PROGRESS: at 7.09% examples, 97540 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:32,903 : INFO : EPOCH 3 - PROGRESS: at 15.06% examples, 100817 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:33,937 : INFO : EPOCH 3 - PROGRESS: at 22.68% examples, 102003 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:34,975 : INFO : EPOCH 3 - PROGRESS: at 30.62% examples, 102664 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:36,005 : INFO : EPOCH 3 - PROGRESS: at 38.96% examples, 103191 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:37,049 : INFO : EPOCH 3 - PROGRESS: at 46.57% examples, 103197 words/s, in_qsize 4, out_qsize 0\n",
            "2019-07-21 13:28:38,085 : INFO : EPOCH 3 - PROGRESS: at 54.05% examples, 103399 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:39,121 : INFO : EPOCH 3 - PROGRESS: at 61.71% examples, 103574 words/s, in_qsize 4, out_qsize 0\n",
            "2019-07-21 13:28:40,134 : INFO : EPOCH 3 - PROGRESS: at 68.47% examples, 103029 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:41,167 : INFO : EPOCH 3 - PROGRESS: at 76.78% examples, 103168 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:42,186 : INFO : EPOCH 3 - PROGRESS: at 84.55% examples, 103394 words/s, in_qsize 4, out_qsize 0\n",
            "2019-07-21 13:28:43,229 : INFO : EPOCH 3 - PROGRESS: at 91.92% examples, 103360 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:44,258 : INFO : EPOCH 3 - PROGRESS: at 99.02% examples, 103459 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:44,326 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-07-21 13:28:44,397 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-07-21 13:28:44,398 : INFO : EPOCH - 3 : training on 1818103 raw words (1404624 effective words) took 13.6s, 103573 effective words/s\n",
            "2019-07-21 13:28:45,469 : INFO : EPOCH 4 - PROGRESS: at 7.09% examples, 94859 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:46,524 : INFO : EPOCH 4 - PROGRESS: at 15.06% examples, 98771 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:47,570 : INFO : EPOCH 4 - PROGRESS: at 22.68% examples, 100187 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:48,626 : INFO : EPOCH 4 - PROGRESS: at 30.62% examples, 100780 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:49,705 : INFO : EPOCH 4 - PROGRESS: at 38.96% examples, 100691 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:50,772 : INFO : EPOCH 4 - PROGRESS: at 46.57% examples, 100789 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:51,821 : INFO : EPOCH 4 - PROGRESS: at 54.05% examples, 101136 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:52,876 : INFO : EPOCH 4 - PROGRESS: at 61.71% examples, 101347 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:53,915 : INFO : EPOCH 4 - PROGRESS: at 69.09% examples, 101587 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:54,983 : INFO : EPOCH 4 - PROGRESS: at 77.28% examples, 101538 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:56,050 : INFO : EPOCH 4 - PROGRESS: at 85.13% examples, 101480 words/s, in_qsize 4, out_qsize 1\n",
            "2019-07-21 13:28:57,083 : INFO : EPOCH 4 - PROGRESS: at 92.42% examples, 101690 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:28:58,110 : INFO : EPOCH 4 - PROGRESS: at 99.54% examples, 101931 words/s, in_qsize 2, out_qsize 0\n",
            "2019-07-21 13:28:58,128 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-07-21 13:28:58,154 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-07-21 13:28:58,155 : INFO : EPOCH - 4 : training on 1818103 raw words (1404821 effective words) took 13.7s, 102206 effective words/s\n",
            "2019-07-21 13:28:59,202 : INFO : EPOCH 5 - PROGRESS: at 7.09% examples, 96929 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:00,257 : INFO : EPOCH 5 - PROGRESS: at 15.06% examples, 99747 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:01,302 : INFO : EPOCH 5 - PROGRESS: at 22.68% examples, 100858 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:02,335 : INFO : EPOCH 5 - PROGRESS: at 30.62% examples, 101868 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:03,357 : INFO : EPOCH 5 - PROGRESS: at 38.96% examples, 102653 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:04,409 : INFO : EPOCH 5 - PROGRESS: at 46.57% examples, 102653 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:05,453 : INFO : EPOCH 5 - PROGRESS: at 54.05% examples, 102792 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:06,498 : INFO : EPOCH 5 - PROGRESS: at 61.71% examples, 102941 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:07,531 : INFO : EPOCH 5 - PROGRESS: at 69.09% examples, 103074 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:08,569 : INFO : EPOCH 5 - PROGRESS: at 77.28% examples, 103177 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:09,622 : INFO : EPOCH 5 - PROGRESS: at 85.13% examples, 103089 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:10,662 : INFO : EPOCH 5 - PROGRESS: at 92.42% examples, 103119 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:11,700 : INFO : EPOCH 5 - PROGRESS: at 99.54% examples, 103169 words/s, in_qsize 2, out_qsize 0\n",
            "2019-07-21 13:29:11,725 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-07-21 13:29:11,758 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-07-21 13:29:11,759 : INFO : EPOCH - 5 : training on 1818103 raw words (1404581 effective words) took 13.6s, 103338 effective words/s\n",
            "2019-07-21 13:29:12,815 : INFO : EPOCH 6 - PROGRESS: at 7.09% examples, 96136 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:13,850 : INFO : EPOCH 6 - PROGRESS: at 15.06% examples, 100312 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:14,876 : INFO : EPOCH 6 - PROGRESS: at 22.68% examples, 101815 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:15,894 : INFO : EPOCH 6 - PROGRESS: at 30.62% examples, 102980 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:16,917 : INFO : EPOCH 6 - PROGRESS: at 38.96% examples, 103583 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:17,949 : INFO : EPOCH 6 - PROGRESS: at 46.57% examples, 103783 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:18,986 : INFO : EPOCH 6 - PROGRESS: at 54.05% examples, 103865 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:19,995 : INFO : EPOCH 6 - PROGRESS: at 61.71% examples, 104311 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:21,021 : INFO : EPOCH 6 - PROGRESS: at 69.09% examples, 104386 words/s, in_qsize 4, out_qsize 0\n",
            "2019-07-21 13:29:22,046 : INFO : EPOCH 6 - PROGRESS: at 77.28% examples, 104471 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:23,104 : INFO : EPOCH 6 - PROGRESS: at 85.13% examples, 104211 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:24,121 : INFO : EPOCH 6 - PROGRESS: at 92.42% examples, 104332 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:25,158 : INFO : EPOCH 6 - PROGRESS: at 99.54% examples, 104313 words/s, in_qsize 2, out_qsize 0\n",
            "2019-07-21 13:29:25,178 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-07-21 13:29:25,236 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-07-21 13:29:25,237 : INFO : EPOCH - 6 : training on 1818103 raw words (1404849 effective words) took 13.5s, 104315 effective words/s\n",
            "2019-07-21 13:29:26,283 : INFO : EPOCH 7 - PROGRESS: at 7.09% examples, 96911 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:27,313 : INFO : EPOCH 7 - PROGRESS: at 15.06% examples, 100976 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:28,356 : INFO : EPOCH 7 - PROGRESS: at 22.68% examples, 101712 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:29,376 : INFO : EPOCH 7 - PROGRESS: at 30.62% examples, 102847 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:30,402 : INFO : EPOCH 7 - PROGRESS: at 38.96% examples, 103369 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:31,457 : INFO : EPOCH 7 - PROGRESS: at 46.57% examples, 103206 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:32,499 : INFO : EPOCH 7 - PROGRESS: at 54.05% examples, 103296 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:33,529 : INFO : EPOCH 7 - PROGRESS: at 61.71% examples, 103571 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:34,561 : INFO : EPOCH 7 - PROGRESS: at 69.09% examples, 103649 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:35,582 : INFO : EPOCH 7 - PROGRESS: at 77.28% examples, 103861 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:36,644 : INFO : EPOCH 7 - PROGRESS: at 85.13% examples, 103631 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:37,669 : INFO : EPOCH 7 - PROGRESS: at 92.42% examples, 103738 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:38,691 : INFO : EPOCH 7 - PROGRESS: at 99.54% examples, 103849 words/s, in_qsize 2, out_qsize 0\n",
            "2019-07-21 13:29:38,711 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-07-21 13:29:38,732 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-07-21 13:29:38,733 : INFO : EPOCH - 7 : training on 1818103 raw words (1404485 effective words) took 13.5s, 104148 effective words/s\n",
            "2019-07-21 13:29:39,766 : INFO : EPOCH 8 - PROGRESS: at 7.09% examples, 98343 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:40,805 : INFO : EPOCH 8 - PROGRESS: at 15.06% examples, 101192 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:41,828 : INFO : EPOCH 8 - PROGRESS: at 22.68% examples, 102490 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:42,845 : INFO : EPOCH 8 - PROGRESS: at 30.62% examples, 103499 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:43,857 : INFO : EPOCH 8 - PROGRESS: at 38.96% examples, 104165 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:44,900 : INFO : EPOCH 8 - PROGRESS: at 46.57% examples, 104030 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:45,939 : INFO : EPOCH 8 - PROGRESS: at 54.05% examples, 104055 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:46,952 : INFO : EPOCH 8 - PROGRESS: at 61.71% examples, 104437 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:47,963 : INFO : EPOCH 8 - PROGRESS: at 69.09% examples, 104633 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:49,005 : INFO : EPOCH 8 - PROGRESS: at 77.28% examples, 104539 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:50,042 : INFO : EPOCH 8 - PROGRESS: at 85.13% examples, 104467 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:51,058 : INFO : EPOCH 8 - PROGRESS: at 92.42% examples, 104569 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:52,085 : INFO : EPOCH 8 - PROGRESS: at 99.54% examples, 104590 words/s, in_qsize 2, out_qsize 0\n",
            "2019-07-21 13:29:52,106 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-07-21 13:29:52,122 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-07-21 13:29:52,123 : INFO : EPOCH - 8 : training on 1818103 raw words (1403605 effective words) took 13.4s, 104921 effective words/s\n",
            "2019-07-21 13:29:53,167 : INFO : EPOCH 9 - PROGRESS: at 7.09% examples, 97131 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:54,210 : INFO : EPOCH 9 - PROGRESS: at 15.06% examples, 100314 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:55,236 : INFO : EPOCH 9 - PROGRESS: at 22.68% examples, 101898 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:56,267 : INFO : EPOCH 9 - PROGRESS: at 30.62% examples, 102717 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:57,292 : INFO : EPOCH 9 - PROGRESS: at 38.96% examples, 103305 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:58,359 : INFO : EPOCH 9 - PROGRESS: at 46.57% examples, 102932 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:29:59,388 : INFO : EPOCH 9 - PROGRESS: at 54.05% examples, 103245 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:00,422 : INFO : EPOCH 9 - PROGRESS: at 61.71% examples, 103497 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:01,448 : INFO : EPOCH 9 - PROGRESS: at 69.09% examples, 103654 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:02,477 : INFO : EPOCH 9 - PROGRESS: at 77.28% examples, 103739 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:03,535 : INFO : EPOCH 9 - PROGRESS: at 85.13% examples, 103571 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:04,554 : INFO : EPOCH 9 - PROGRESS: at 92.42% examples, 103707 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:05,593 : INFO : EPOCH 9 - PROGRESS: at 99.54% examples, 103701 words/s, in_qsize 2, out_qsize 0\n",
            "2019-07-21 13:30:05,619 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-07-21 13:30:05,663 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-07-21 13:30:05,664 : INFO : EPOCH - 9 : training on 1818103 raw words (1404085 effective words) took 13.5s, 103776 effective words/s\n",
            "2019-07-21 13:30:06,726 : INFO : EPOCH 10 - PROGRESS: at 7.09% examples, 95275 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:07,760 : INFO : EPOCH 10 - PROGRESS: at 15.06% examples, 99869 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:08,795 : INFO : EPOCH 10 - PROGRESS: at 22.68% examples, 101249 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:09,811 : INFO : EPOCH 10 - PROGRESS: at 30.62% examples, 102573 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:10,826 : INFO : EPOCH 10 - PROGRESS: at 38.96% examples, 103389 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:11,858 : INFO : EPOCH 10 - PROGRESS: at 46.57% examples, 103576 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:12,882 : INFO : EPOCH 10 - PROGRESS: at 54.05% examples, 103885 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:13,905 : INFO : EPOCH 10 - PROGRESS: at 61.71% examples, 104176 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:14,947 : INFO : EPOCH 10 - PROGRESS: at 69.09% examples, 104078 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:15,964 : INFO : EPOCH 10 - PROGRESS: at 77.28% examples, 104273 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:17,007 : INFO : EPOCH 10 - PROGRESS: at 85.13% examples, 104176 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:18,013 : INFO : EPOCH 10 - PROGRESS: at 92.42% examples, 104403 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:19,031 : INFO : EPOCH 10 - PROGRESS: at 99.54% examples, 104513 words/s, in_qsize 2, out_qsize 0\n",
            "2019-07-21 13:30:19,046 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-07-21 13:30:19,136 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-07-21 13:30:19,137 : INFO : EPOCH - 10 : training on 1818103 raw words (1404259 effective words) took 13.5s, 104309 effective words/s\n",
            "2019-07-21 13:30:20,178 : INFO : EPOCH 11 - PROGRESS: at 7.09% examples, 97231 words/s, in_qsize 4, out_qsize 0\n",
            "2019-07-21 13:30:21,208 : INFO : EPOCH 11 - PROGRESS: at 15.06% examples, 101162 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:22,253 : INFO : EPOCH 11 - PROGRESS: at 22.68% examples, 101796 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:23,286 : INFO : EPOCH 11 - PROGRESS: at 30.62% examples, 102593 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:24,305 : INFO : EPOCH 11 - PROGRESS: at 38.96% examples, 103292 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:25,359 : INFO : EPOCH 11 - PROGRESS: at 46.57% examples, 103160 words/s, in_qsize 4, out_qsize 1\n",
            "2019-07-21 13:30:26,412 : INFO : EPOCH 11 - PROGRESS: at 54.05% examples, 103144 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:27,427 : INFO : EPOCH 11 - PROGRESS: at 61.71% examples, 103604 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:28,445 : INFO : EPOCH 11 - PROGRESS: at 69.09% examples, 103830 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:29,468 : INFO : EPOCH 11 - PROGRESS: at 77.28% examples, 104014 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:30,503 : INFO : EPOCH 11 - PROGRESS: at 85.13% examples, 103994 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:31,530 : INFO : EPOCH 11 - PROGRESS: at 92.42% examples, 104059 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:32,552 : INFO : EPOCH 11 - PROGRESS: at 99.54% examples, 104162 words/s, in_qsize 2, out_qsize 0\n",
            "2019-07-21 13:30:32,572 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-07-21 13:30:32,576 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-07-21 13:30:32,577 : INFO : EPOCH - 11 : training on 1818103 raw words (1404495 effective words) took 13.4s, 104588 effective words/s\n",
            "2019-07-21 13:30:33,620 : INFO : EPOCH 12 - PROGRESS: at 7.09% examples, 97361 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:34,663 : INFO : EPOCH 12 - PROGRESS: at 15.06% examples, 100577 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:35,693 : INFO : EPOCH 12 - PROGRESS: at 22.68% examples, 101903 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:36,745 : INFO : EPOCH 12 - PROGRESS: at 30.62% examples, 102236 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:37,758 : INFO : EPOCH 12 - PROGRESS: at 38.96% examples, 103134 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:38,803 : INFO : EPOCH 12 - PROGRESS: at 46.57% examples, 103135 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:39,837 : INFO : EPOCH 12 - PROGRESS: at 54.05% examples, 103351 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:40,881 : INFO : EPOCH 12 - PROGRESS: at 61.71% examples, 103446 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:41,913 : INFO : EPOCH 12 - PROGRESS: at 69.09% examples, 103525 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:42,945 : INFO : EPOCH 12 - PROGRESS: at 77.28% examples, 103644 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:43,978 : INFO : EPOCH 12 - PROGRESS: at 85.13% examples, 103701 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:45,007 : INFO : EPOCH 12 - PROGRESS: at 92.42% examples, 103746 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:46,040 : INFO : EPOCH 12 - PROGRESS: at 99.54% examples, 103790 words/s, in_qsize 2, out_qsize 0\n",
            "2019-07-21 13:30:46,059 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-07-21 13:30:46,065 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-07-21 13:30:46,067 : INFO : EPOCH - 12 : training on 1818103 raw words (1404429 effective words) took 13.5s, 104204 effective words/s\n",
            "2019-07-21 13:30:47,117 : INFO : EPOCH 13 - PROGRESS: at 7.09% examples, 96596 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:48,151 : INFO : EPOCH 13 - PROGRESS: at 15.06% examples, 100602 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:49,193 : INFO : EPOCH 13 - PROGRESS: at 22.68% examples, 101526 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:50,235 : INFO : EPOCH 13 - PROGRESS: at 30.62% examples, 102201 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:51,260 : INFO : EPOCH 13 - PROGRESS: at 38.96% examples, 102871 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:52,304 : INFO : EPOCH 13 - PROGRESS: at 46.57% examples, 102964 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:53,340 : INFO : EPOCH 13 - PROGRESS: at 54.05% examples, 103158 words/s, in_qsize 4, out_qsize 1\n",
            "2019-07-21 13:30:54,366 : INFO : EPOCH 13 - PROGRESS: at 61.71% examples, 103506 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:55,390 : INFO : EPOCH 13 - PROGRESS: at 69.09% examples, 103660 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:56,454 : INFO : EPOCH 13 - PROGRESS: at 77.28% examples, 103434 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:57,487 : INFO : EPOCH 13 - PROGRESS: at 85.13% examples, 103492 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:58,518 : INFO : EPOCH 13 - PROGRESS: at 92.42% examples, 103551 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:30:59,536 : INFO : EPOCH 13 - PROGRESS: at 99.54% examples, 103728 words/s, in_qsize 2, out_qsize 0\n",
            "2019-07-21 13:30:59,557 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-07-21 13:30:59,583 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-07-21 13:30:59,585 : INFO : EPOCH - 13 : training on 1818103 raw words (1404405 effective words) took 13.5s, 103978 effective words/s\n",
            "2019-07-21 13:31:00,631 : INFO : EPOCH 14 - PROGRESS: at 7.09% examples, 96960 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:01,660 : INFO : EPOCH 14 - PROGRESS: at 15.06% examples, 101059 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:02,711 : INFO : EPOCH 14 - PROGRESS: at 22.68% examples, 101579 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:03,743 : INFO : EPOCH 14 - PROGRESS: at 30.62% examples, 102461 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:04,787 : INFO : EPOCH 14 - PROGRESS: at 38.96% examples, 102719 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:05,842 : INFO : EPOCH 14 - PROGRESS: at 46.57% examples, 102671 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:06,909 : INFO : EPOCH 14 - PROGRESS: at 54.05% examples, 102463 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:07,927 : INFO : EPOCH 14 - PROGRESS: at 61.71% examples, 102980 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:08,971 : INFO : EPOCH 14 - PROGRESS: at 69.09% examples, 102994 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:10,005 : INFO : EPOCH 14 - PROGRESS: at 77.28% examples, 103138 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:11,037 : INFO : EPOCH 14 - PROGRESS: at 85.13% examples, 103254 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:12,058 : INFO : EPOCH 14 - PROGRESS: at 92.42% examples, 103420 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:13,082 : INFO : EPOCH 14 - PROGRESS: at 99.54% examples, 103548 words/s, in_qsize 2, out_qsize 0\n",
            "2019-07-21 13:31:13,112 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-07-21 13:31:13,146 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-07-21 13:31:13,147 : INFO : EPOCH - 14 : training on 1818103 raw words (1404748 effective words) took 13.6s, 103666 effective words/s\n",
            "2019-07-21 13:31:14,192 : INFO : EPOCH 15 - PROGRESS: at 7.09% examples, 96830 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:15,227 : INFO : EPOCH 15 - PROGRESS: at 15.06% examples, 100612 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:16,266 : INFO : EPOCH 15 - PROGRESS: at 22.68% examples, 101598 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:17,288 : INFO : EPOCH 15 - PROGRESS: at 30.62% examples, 102711 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:18,306 : INFO : EPOCH 15 - PROGRESS: at 38.96% examples, 103412 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:19,340 : INFO : EPOCH 15 - PROGRESS: at 46.57% examples, 103582 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:20,377 : INFO : EPOCH 15 - PROGRESS: at 54.05% examples, 103713 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:21,398 : INFO : EPOCH 15 - PROGRESS: at 61.71% examples, 104072 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:22,434 : INFO : EPOCH 15 - PROGRESS: at 69.09% examples, 104069 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:23,451 : INFO : EPOCH 15 - PROGRESS: at 77.28% examples, 104258 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:24,515 : INFO : EPOCH 15 - PROGRESS: at 85.13% examples, 103971 words/s, in_qsize 4, out_qsize 0\n",
            "2019-07-21 13:31:25,545 : INFO : EPOCH 15 - PROGRESS: at 92.42% examples, 104008 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:26,592 : INFO : EPOCH 15 - PROGRESS: at 99.54% examples, 103910 words/s, in_qsize 2, out_qsize 0\n",
            "2019-07-21 13:31:26,612 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-07-21 13:31:26,613 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-07-21 13:31:26,615 : INFO : EPOCH - 15 : training on 1818103 raw words (1404380 effective words) took 13.5s, 104353 effective words/s\n",
            "2019-07-21 13:31:27,659 : INFO : EPOCH 16 - PROGRESS: at 7.09% examples, 97347 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:28,685 : INFO : EPOCH 16 - PROGRESS: at 15.06% examples, 101413 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:29,718 : INFO : EPOCH 16 - PROGRESS: at 22.68% examples, 102400 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:30,748 : INFO : EPOCH 16 - PROGRESS: at 30.62% examples, 103118 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:31,763 : INFO : EPOCH 16 - PROGRESS: at 38.96% examples, 103790 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:32,823 : INFO : EPOCH 16 - PROGRESS: at 46.57% examples, 103490 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:33,859 : INFO : EPOCH 16 - PROGRESS: at 54.05% examples, 103636 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:34,889 : INFO : EPOCH 16 - PROGRESS: at 61.71% examples, 103864 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:35,911 : INFO : EPOCH 16 - PROGRESS: at 69.09% examples, 104019 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:36,953 : INFO : EPOCH 16 - PROGRESS: at 77.28% examples, 103988 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:37,993 : INFO : EPOCH 16 - PROGRESS: at 85.13% examples, 103948 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:39,006 : INFO : EPOCH 16 - PROGRESS: at 92.42% examples, 104117 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:40,015 : INFO : EPOCH 16 - PROGRESS: at 99.54% examples, 104305 words/s, in_qsize 2, out_qsize 0\n",
            "2019-07-21 13:31:40,033 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-07-21 13:31:40,071 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-07-21 13:31:40,072 : INFO : EPOCH - 16 : training on 1818103 raw words (1404596 effective words) took 13.4s, 104487 effective words/s\n",
            "2019-07-21 13:31:41,124 : INFO : EPOCH 17 - PROGRESS: at 7.09% examples, 96427 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:42,162 : INFO : EPOCH 17 - PROGRESS: at 15.06% examples, 100356 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:43,190 : INFO : EPOCH 17 - PROGRESS: at 22.68% examples, 101798 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:44,215 : INFO : EPOCH 17 - PROGRESS: at 30.62% examples, 102784 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:45,235 : INFO : EPOCH 17 - PROGRESS: at 38.96% examples, 103453 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:46,281 : INFO : EPOCH 17 - PROGRESS: at 46.57% examples, 103404 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:47,316 : INFO : EPOCH 17 - PROGRESS: at 54.05% examples, 103567 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:48,345 : INFO : EPOCH 17 - PROGRESS: at 61.71% examples, 103805 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:49,370 : INFO : EPOCH 17 - PROGRESS: at 69.09% examples, 103950 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:50,397 : INFO : EPOCH 17 - PROGRESS: at 77.28% examples, 104053 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:51,443 : INFO : EPOCH 17 - PROGRESS: at 85.13% examples, 103953 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:52,467 : INFO : EPOCH 17 - PROGRESS: at 92.42% examples, 104037 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:53,482 : INFO : EPOCH 17 - PROGRESS: at 99.54% examples, 104187 words/s, in_qsize 2, out_qsize 0\n",
            "2019-07-21 13:31:53,499 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-07-21 13:31:53,520 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-07-21 13:31:53,521 : INFO : EPOCH - 17 : training on 1818103 raw words (1404456 effective words) took 13.4s, 104511 effective words/s\n",
            "2019-07-21 13:31:54,576 : INFO : EPOCH 18 - PROGRESS: at 7.09% examples, 96140 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:55,613 : INFO : EPOCH 18 - PROGRESS: at 15.06% examples, 100245 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:56,664 : INFO : EPOCH 18 - PROGRESS: at 22.68% examples, 101047 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:57,701 : INFO : EPOCH 18 - PROGRESS: at 30.62% examples, 101902 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:58,730 : INFO : EPOCH 18 - PROGRESS: at 38.96% examples, 102537 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:31:59,779 : INFO : EPOCH 18 - PROGRESS: at 46.57% examples, 102606 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:00,821 : INFO : EPOCH 18 - PROGRESS: at 54.05% examples, 102801 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:01,849 : INFO : EPOCH 18 - PROGRESS: at 61.71% examples, 103154 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:02,887 : INFO : EPOCH 18 - PROGRESS: at 69.09% examples, 103217 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:03,916 : INFO : EPOCH 18 - PROGRESS: at 77.28% examples, 103386 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:04,980 : INFO : EPOCH 18 - PROGRESS: at 85.13% examples, 103183 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:06,009 : INFO : EPOCH 18 - PROGRESS: at 92.42% examples, 103290 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:07,063 : INFO : EPOCH 18 - PROGRESS: at 99.54% examples, 103202 words/s, in_qsize 2, out_qsize 0\n",
            "2019-07-21 13:32:07,088 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-07-21 13:32:07,121 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-07-21 13:32:07,123 : INFO : EPOCH - 18 : training on 1818103 raw words (1404666 effective words) took 13.6s, 103358 effective words/s\n",
            "2019-07-21 13:32:08,167 : INFO : EPOCH 19 - PROGRESS: at 7.09% examples, 97039 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:09,209 : INFO : EPOCH 19 - PROGRESS: at 15.06% examples, 100527 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:10,243 : INFO : EPOCH 19 - PROGRESS: at 22.68% examples, 101730 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:11,288 : INFO : EPOCH 19 - PROGRESS: at 30.62% examples, 102281 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:12,309 : INFO : EPOCH 19 - PROGRESS: at 38.96% examples, 103005 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:13,356 : INFO : EPOCH 19 - PROGRESS: at 46.57% examples, 103013 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:14,386 : INFO : EPOCH 19 - PROGRESS: at 54.05% examples, 103292 words/s, in_qsize 2, out_qsize 1\n",
            "2019-07-21 13:32:15,419 : INFO : EPOCH 19 - PROGRESS: at 61.71% examples, 103498 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:16,439 : INFO : EPOCH 19 - PROGRESS: at 69.09% examples, 103701 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:17,462 : INFO : EPOCH 19 - PROGRESS: at 77.28% examples, 103881 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:18,512 : INFO : EPOCH 19 - PROGRESS: at 85.13% examples, 103760 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:19,523 : INFO : EPOCH 19 - PROGRESS: at 92.42% examples, 103956 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:20,549 : INFO : EPOCH 19 - PROGRESS: at 99.54% examples, 104022 words/s, in_qsize 2, out_qsize 0\n",
            "2019-07-21 13:32:20,574 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-07-21 13:32:20,581 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-07-21 13:32:20,583 : INFO : EPOCH - 19 : training on 1818103 raw words (1403717 effective words) took 13.4s, 104388 effective words/s\n",
            "2019-07-21 13:32:21,627 : INFO : EPOCH 20 - PROGRESS: at 7.09% examples, 96753 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:22,669 : INFO : EPOCH 20 - PROGRESS: at 15.06% examples, 100286 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:23,698 : INFO : EPOCH 20 - PROGRESS: at 22.68% examples, 101698 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:24,718 : INFO : EPOCH 20 - PROGRESS: at 30.62% examples, 102829 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:25,746 : INFO : EPOCH 20 - PROGRESS: at 38.96% examples, 103309 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:26,794 : INFO : EPOCH 20 - PROGRESS: at 46.57% examples, 103271 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:27,827 : INFO : EPOCH 20 - PROGRESS: at 54.05% examples, 103510 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:28,864 : INFO : EPOCH 20 - PROGRESS: at 61.71% examples, 103674 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:29,895 : INFO : EPOCH 20 - PROGRESS: at 69.09% examples, 103742 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:30,934 : INFO : EPOCH 20 - PROGRESS: at 77.28% examples, 103772 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:32,003 : INFO : EPOCH 20 - PROGRESS: at 85.13% examples, 103485 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:33,040 : INFO : EPOCH 20 - PROGRESS: at 92.42% examples, 103490 words/s, in_qsize 3, out_qsize 0\n",
            "2019-07-21 13:32:34,095 : INFO : EPOCH 20 - PROGRESS: at 99.54% examples, 103371 words/s, in_qsize 2, out_qsize 0\n",
            "2019-07-21 13:32:34,112 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-07-21 13:32:34,120 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-07-21 13:32:34,122 : INFO : EPOCH - 20 : training on 1818103 raw words (1404179 effective words) took 13.5s, 103783 effective words/s\n",
            "2019-07-21 13:32:34,123 : INFO : training on a 36362060 raw words (28088626 effective words) took 270.2s, 103960 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28088626, 36362060)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK3K-yKKtOXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists(\"trained\"):\n",
        "    os.makedirs(\"trained\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-X4HKjWvDn6",
        "colab_type": "code",
        "outputId": "11d148ae-5018-436e-a180-7f5f0f977d03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "thrones2vec.save(os.path.join(\"trained\", \"thrones2vec.w2v\"))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-07-21 13:33:03,564 : INFO : saving Word2Vec object under trained/thrones2vec.w2v, separately None\n",
            "2019-07-21 13:33:03,566 : INFO : not storing attribute vectors_norm\n",
            "2019-07-21 13:33:03,568 : INFO : not storing attribute cum_table\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "2019-07-21 13:33:04,203 : INFO : saved trained/thrones2vec.w2v\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Af27xzwvFbG",
        "colab_type": "code",
        "outputId": "0e183d41-41b6-42e4-c992-8ebccb85659f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "thrones2vec = w2v.Word2Vec.load(os.path.join(\"trained\", \"thrones2vec.w2v\"))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-07-21 13:33:29,336 : INFO : loading Word2Vec object from trained/thrones2vec.w2v\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "2019-07-21 13:33:29,708 : INFO : loading wv recursively from trained/thrones2vec.w2v.wv.* with mmap=None\n",
            "2019-07-21 13:33:29,710 : INFO : setting ignored attribute vectors_norm to None\n",
            "2019-07-21 13:33:29,711 : INFO : loading vocabulary recursively from trained/thrones2vec.w2v.vocabulary.* with mmap=None\n",
            "2019-07-21 13:33:29,712 : INFO : loading trainables recursively from trained/thrones2vec.w2v.trainables.* with mmap=None\n",
            "2019-07-21 13:33:29,713 : INFO : setting ignored attribute cum_table to None\n",
            "2019-07-21 13:33:29,714 : INFO : loaded trained/thrones2vec.w2v\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj1K3fvOvLux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#my video - how to visualize a dataset easily\n",
        "tsne = sklearn.manifold.TSNE(n_components=2, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K7oSfUJvU1s",
        "colab_type": "code",
        "outputId": "74cafcb1-8971-43a4-9150-fb4d859d96ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "all_word_vectors_matrix = thrones2vec.syn0_lockf\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0_lockf` (Attribute will be removed in 4.0.0, use self.trainables.vectors_lockf instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFNvvjE8vWhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_word_vectors_matrix.reshape(-1,1)\n",
        "\n",
        "all_word_vectors_matrix_2d = tsne.fit_transform(all_word_vectors_matrix.reshape(-1,1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsYi65z6ww3U",
        "colab_type": "code",
        "outputId": "72c48584-be07-4393-a2ab-8717c1b1c9bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "thrones2vec.most_similar(\"Stark\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "2019-07-21 13:45:40,102 : INFO : precomputing L2-norms of word weight vectors\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Eddard', 0.6249960064888),\n",
              " ('executed', 0.48581451177597046),\n",
              " ('Snowbeard', 0.4553941488265991),\n",
              " ('divulge', 0.4551628530025482),\n",
              " ('fishwife', 0.4469717741012573),\n",
              " ('Winterfell', 0.4451400935649872),\n",
              " ('SHIREI', 0.44483068585395813),\n",
              " ('Edrick', 0.4339056611061096),\n",
              " ('Underfoot', 0.43169105052948),\n",
              " ('Knelt', 0.4296530783176422)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_nry0U4yERk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}